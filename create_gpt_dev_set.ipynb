{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gptcache import GPTCache\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Can you create three true and three false claims related to this factual statement? \n",
    "\n",
    "\"{claim}\"\n",
    "\n",
    "Can you provide your answer as Python lists named true_claims and false_claims?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4\"\n",
    "cache = GPTCache(\n",
    "            cache_loc=f\"cache/cache_{model_name}.json\",\n",
    "            key_loc=\"openai_key.txt\",\n",
    "            engine=model_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_true_false_lists(st):\n",
    "    try:\n",
    "        true_start = st.find(\"rue_claims = [\")\n",
    "        true_end = st.find(\"]\", true_start)\n",
    "        false_start = st.find(\"alse_claims = [\")\n",
    "        false_end = st.find(\"]\", false_start)\n",
    "        true_claims = st[true_start:true_end+1]\n",
    "        true_claims = true_claims[true_claims.find(\"[\"):]\n",
    "        false_claims = st[false_start:false_end+1]\n",
    "        false_claims = false_claims[false_claims.find(\"[\"):]\n",
    "        return eval(true_claims), eval(false_claims)\n",
    "    except:\n",
    "        print(st)\n",
    "        print(true_claims)\n",
    "        print(false_claims)\n",
    "        print(\"---\")\n",
    "        return [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fine-tuning dataset.\n",
    "input_prompt = \"\"\"[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{user_msg} [/INST]\"\"\"\n",
    "system_prompt = \"Evaluate the following claim and answer only with true or false.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating...: 100%|██████████| 503/503 [00:00<00:00, 942687.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, but the statement \"they are blood related so it is true Twin s.\" is a bit confusing, and doesn't provide enough clear fact to make true or false statements about. It is not clear whether we're talking about blood relation influencing twinning or something else. Please clarify the context or provide more detailed facts.\n",
      "\n",
      "\n",
      "---\n",
      "Sure, here is your requested Python lists:\n",
      "\n",
      "```python\n",
      "true_claims = [\"Bengal fox and Arctic fox both belong to the family Canidae.\", \n",
      "               \"Bengal fox and Arctic fox are both types of foxes.\", \n",
      "               \"Bengal fox and Arctic fox are both members of the Vulpes genus.\"]\n",
      "\n",
      "false_claims  = [\"Bengal fox and Arctic fox both live in the same habitat.\", \n",
      "                 \"Bengal fox and Arctic fox originate from the same geographical location.\", \n",
      "                 \"Bengal fox and Arctic fox have the same adaptations for cold environments.\"]\n",
      "```\n",
      "[\"Bengal fox and Arctic fox both belong to the family Canidae.\", \n",
      "               \"Bengal fox and Arctic fox are both types of foxes.\", \n",
      "               \"Bengal fox and Arctic fox are both members of the Vulpes genus.\"]\n",
      "\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for num in [10, 30, 50, 100]:\n",
    "    creak_train = pd.read_json(\"/projectnb/llamagrp/feyzanb/creak/data/creak/train.json\", lines=True)\n",
    "    creak_train = creak_train[['sentence', 'label']][:num]\n",
    "    creak_train = creak_train.loc[creak_train['label'] == \"true\"]\n",
    "    creak_train['prompt'] = creak_train['sentence'].apply(lambda x: prompt.format(claim=x))\n",
    "    queries = creak_train['prompt'].tolist()\n",
    "    preds = []\n",
    "    for q in tqdm(queries, desc=\"Generating...\"):\n",
    "        preds.append(cache.generate(q, max_length=500))\n",
    "    preds = [parse_true_false_lists(p) for p in preds]\n",
    "    true_claims = [p[0] for p in preds]\n",
    "    false_claims = [p[1] for p in preds]\n",
    "    true_claims = [item for sublist in true_claims for item in sublist]\n",
    "    false_claims = [item for sublist in false_claims for item in sublist]\n",
    "\n",
    "    rel_claims = true_claims + false_claims\n",
    "    labels = [\"True.\"] * len(true_claims) + [\"False.\"] * len(false_claims)\n",
    "\n",
    "    rel = pd.DataFrame({\"label\": labels, \"input_prompt\": rel_claims})\n",
    "    rel['input_prompt'] = rel['input_prompt'].apply(lambda x: input_prompt.format(system_prompt=system_prompt, user_msg=x))\n",
    "    rel.to_csv(f\"creak_n{num}/rel_dev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3006"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
